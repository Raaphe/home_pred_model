{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Value Prediction Model\n",
    "---\n",
    "\n",
    "This model will use the usa-real-estate dataset of data scraped from `realtor.com`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import utils;\n",
    "from sklearn.preprocessing import LabelEncoder;\n",
    "from sklearn.model_selection import train_test_split;\n",
    "import torch;\n",
    "from torch import nn;\n",
    "from torch.utils.data import DataLoader, Dataset;\n",
    "from tqdm.auto import tqdm;\n",
    "from typing import Tuple\n",
    "import torch.onnx;\n",
    "\n",
    "DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\";\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   brokered_by    status     price  bed  bath  acre_lot     street  \\\n",
       " 0     103378.0  for_sale  105000.0  3.0   2.0      0.12  1962661.0   \n",
       " 1      52707.0  for_sale   80000.0  4.0   2.0      0.08  1902874.0   \n",
       " 2     103379.0  for_sale   67000.0  2.0   1.0      0.15  1404990.0   \n",
       " 3      31239.0  for_sale  145000.0  4.0   2.0      0.10  1947675.0   \n",
       " 4      34632.0  for_sale   65000.0  6.0   2.0      0.05   331151.0   \n",
       " \n",
       "          city        state  zip_code  house_size prev_sold_date  \n",
       " 0    Adjuntas  Puerto Rico     601.0       920.0            NaN  \n",
       " 1    Adjuntas  Puerto Rico     601.0      1527.0            NaN  \n",
       " 2  Juana Diaz  Puerto Rico     795.0       748.0            NaN  \n",
       " 3       Ponce  Puerto Rico     731.0      1800.0            NaN  \n",
       " 4    Mayaguez  Puerto Rico     680.0         NaN            NaN  ,\n",
       " Index(['brokered_by', 'status', 'price', 'bed', 'bath', 'acre_lot', 'street',\n",
       "        'city', 'state', 'zip_code', 'house_size', 'prev_sold_date'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"realtor-data.zip.csv\");\n",
    "df.head(5), df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "---\n",
    "\n",
    "in this section, I have a lot of bad data, I will have two renditions of my dataframe, one with missing data replaced by the median, one replaced by the mean, and one with missing data fully removed. They will be placed in `whole_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOKING AT DF size(1414373)\n",
      "+====\n",
      "\n",
      "| FEATURE price :\n",
      "| NULL COUNT -> 1296 | NaN COUNT -> 1296 | NONE COUNT -> 0\n",
      "| TOTAL MISSING VALUES 2592 -> 0.18%\n",
      "---\n",
      "| FEATURE bed :\n",
      "| NULL COUNT -> 411343 | NaN COUNT -> 411343 | NONE COUNT -> 0\n",
      "| TOTAL MISSING VALUES 822686 -> 58.17%\n",
      "---\n",
      "| FEATURE bath :\n",
      "| NULL COUNT -> 433842 | NaN COUNT -> 433842 | NONE COUNT -> 0\n",
      "| TOTAL MISSING VALUES 867684 -> 61.35%\n",
      "---\n",
      "| FEATURE acre_lot :\n",
      "| NULL COUNT -> 217967 | NaN COUNT -> 217967 | NONE COUNT -> 0\n",
      "| TOTAL MISSING VALUES 435934 -> 30.82%\n",
      "---\n",
      "| FEATURE state :\n",
      "| NULL COUNT -> 8 | NaN COUNT -> 8 | NONE COUNT -> 0\n",
      "| TOTAL MISSING VALUES 16 -> 0.00%\n",
      "---\n",
      "| FEATURE zip_code :\n",
      "| NULL COUNT -> 287 | NaN COUNT -> 287 | NONE COUNT -> 0\n",
      "| TOTAL MISSING VALUES 574 -> 0.04%\n",
      "---\n",
      "| FEATURE house_size :\n",
      "| NULL COUNT -> 464774 | NaN COUNT -> 464774 | NONE COUNT -> 0\n",
      "| TOTAL MISSING VALUES 929548 -> 65.72%\n",
      "---\n",
      "\n",
      "+====\n",
      "\n",
      "\n",
      "After Cleaning\n",
      "\n",
      "LOOKING AT DF size(1412785)\n",
      "+====\n",
      "\n",
      "| FEATURE price CONTAINS NO EMPTY VALUES ++\n",
      "---\n",
      "| FEATURE bed CONTAINS NO EMPTY VALUES ++\n",
      "---\n",
      "| FEATURE bath CONTAINS NO EMPTY VALUES ++\n",
      "---\n",
      "| FEATURE acre_lot CONTAINS NO EMPTY VALUES ++\n",
      "---\n",
      "| FEATURE state CONTAINS NO EMPTY VALUES ++\n",
      "---\n",
      "| FEATURE zip_code CONTAINS NO EMPTY VALUES ++\n",
      "---\n",
      "| FEATURE house_size CONTAINS NO EMPTY VALUES ++\n",
      "---\n",
      "\n",
      "+====\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1412785,\n",
       "       price  bed  bath  acre_lot  state  zip_code  house_size\n",
       " 0  105000.0  3.0   2.0      0.12     40     601.0       920.0\n",
       " 1   80000.0  4.0   2.0      0.08     40     601.0      1527.0\n",
       " 2   67000.0  2.0   1.0      0.15     40     795.0       748.0\n",
       " 3  145000.0  4.0   2.0      0.10     40     731.0      1800.0\n",
       " 4   65000.0  6.0   2.0      0.05     40     680.0      1822.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_outlier_mode: str = \"median\"; # median | stripped | mean\n",
    "\n",
    "# Only operating on listings for sale\n",
    "whole_df = df[df['status'] != \"sold\"];\n",
    "\n",
    "# Street encoded value cannot be reproduced when given new data.\n",
    "# prev_sold_date useless, not a time series problem.\n",
    "whole_df = whole_df.drop(columns=['street', 'status', 'prev_sold_date', 'city', 'brokered_by'], axis=1);\n",
    "\n",
    "# Before Cleaning\n",
    "utils.dataFrameStatus(whole_df)\n",
    "\n",
    "if dataset_outlier_mode == \"mean\":\n",
    "    whole_df['bed'] = whole_df['bed'].fillna(whole_df['bed'].mean());\n",
    "    whole_df['bath'] = whole_df['bath'].fillna(whole_df['bath'].mean());\n",
    "    whole_df['acre_lot'] = whole_df['acre_lot'].fillna(whole_df['acre_lot'].mean());\n",
    "    whole_df['house_size'] = whole_df['house_size'].fillna(whole_df['house_size'].mean());\n",
    "elif dataset_outlier_mode == \"median\":\n",
    "    whole_df['bed'] = whole_df['bed'].fillna(whole_df['bed'].median());\n",
    "    whole_df['bath'] = whole_df['bath'].fillna(whole_df['bath'].median());\n",
    "    whole_df['acre_lot'] = whole_df['acre_lot'].fillna(whole_df['acre_lot'].median());\n",
    "    whole_df['house_size'] = whole_df['house_size'].fillna(whole_df['house_size'].median());\n",
    "\n",
    "whole_df = whole_df.dropna();\n",
    "\n",
    "state_map = {\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Virgin Islands': 'VI',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Connecticut': 'CT',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New York': 'NY',\n",
    "    'New Hampshire': 'NH',\n",
    "    'Vermont': 'VT',\n",
    "    'Rhode Island': 'RI',\n",
    "    'Wyoming': 'WY',\n",
    "    'Maine': 'ME',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Delaware': 'DE',\n",
    "    'Ohio': 'OH',\n",
    "    'Maryland': 'MD',\n",
    "    'Virginia': 'VA',\n",
    "    'Colorado': 'CO',\n",
    "    'District of Columbia': 'DC',\n",
    "    'North Carolina': 'NC',\n",
    "    'Kentucky': 'KY',\n",
    "    'South Carolina': 'SC',\n",
    "    'Tennessee': 'TN',\n",
    "    'Georgia': 'GA',\n",
    "    'Alabama': 'AL',\n",
    "    'Florida': 'FL',\n",
    "    'Mississippi': 'MS',\n",
    "    'Texas': 'TX',\n",
    "    'Missouri': 'MO',\n",
    "    'Arkansas': 'AR',\n",
    "    'Louisiana': 'LA',\n",
    "    'Indiana': 'IN',\n",
    "    'Illinois': 'IL',\n",
    "    'Michigan': 'MI',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Iowa': 'IA',\n",
    "    'Minnesota': 'MN',\n",
    "    'South Dakota': 'SD',\n",
    "    'Nebraska': 'NE',\n",
    "    'North Dakota': 'ND',\n",
    "    'Montana': 'MT',\n",
    "    'Idaho': 'ID',\n",
    "    'Kansas': 'KS',\n",
    "    'Oklahoma': 'OK',\n",
    "    'New Mexico': 'NM',\n",
    "    'Utah': 'UT',\n",
    "    'Nevada': 'NV',\n",
    "    'Washington': 'WA',\n",
    "    'Oregon': 'OR',\n",
    "    'Arizona': 'AZ',\n",
    "    'California': 'CA',\n",
    "    'Hawaii': 'HI',\n",
    "    'Guam': 'GU',\n",
    "    'Alaska': 'AK'\n",
    "}\n",
    "\n",
    "whole_df['state'] = whole_df['state'].map(state_map);\n",
    "\n",
    "le = LabelEncoder();\n",
    "whole_df['state'] = le.fit_transform(whole_df['state']);\n",
    "\n",
    "# After Cleaning\n",
    "print(\"\\nAfter Cleaning\\n\");\n",
    "utils.dataFrameStatus(whole_df)\n",
    "len(whole_df), whole_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[4.0000e+00, 3.0000e+00, 2.0000e+01, 3.7000e+01, 7.3857e+04, 2.1250e+03],\n",
       "          [3.0000e+00, 3.0000e+00, 3.3000e-01, 4.5000e+01, 7.7384e+04, 3.0800e+03],\n",
       "          [4.0000e+00, 4.0000e+00, 1.0700e+00, 1.5000e+01, 6.0014e+04, 4.2380e+03],\n",
       "          [4.0000e+00, 2.0000e+00, 4.1000e-01, 1.3000e+01, 5.2803e+04, 4.1780e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 1.3000e-01, 1.4000e+01, 8.3815e+04, 1.3970e+03],\n",
       "          [3.0000e+00, 3.0000e+00, 3.3000e-01, 4.3000e+01, 5.7032e+04, 1.4460e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 1.4400e+01, 3.8000e+01, 9.7405e+04, 1.8220e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 1.0000e+00, 2.3000e+01, 4.9637e+04, 1.8220e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 9.8000e+01, 1.0000e+01, 3.1036e+04, 1.8220e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 8.0000e-02, 4.0000e+00, 9.4123e+04, 1.8220e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 2.1500e+00, 4.2000e+01, 2.9906e+04, 1.8220e+03],\n",
       "          [4.0000e+00, 3.0000e+00, 2.1500e+00, 4.7000e+01, 2.2972e+04, 1.6100e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 3.5000e-01, 1.0000e+01, 3.1210e+04, 1.8220e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 3.0000e-01, 1.3000e+01, 5.0201e+04, 1.8220e+03],\n",
       "          [2.0000e+00, 2.0000e+00, 3.3100e+00, 4.0000e+00, 9.0804e+04, 1.4200e+03],\n",
       "          [3.0000e+00, 3.0000e+00, 4.0000e-02, 9.0000e+00, 3.3610e+04, 1.6940e+03],\n",
       "          [3.0000e+00, 1.0000e+00, 3.3000e-01, 9.0000e+00, 3.2118e+04, 4.2700e+02],\n",
       "          [3.0000e+00, 2.0000e+00, 5.9000e+00, 3.2000e+01, 8.0560e+03, 1.8220e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 4.5000e-01, 4.0000e+00, 9.1040e+04, 1.7440e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 4.0000e-02, 2.1000e+01, 2.1222e+04, 1.1620e+03],\n",
       "          [2.0000e+00, 3.0000e+00, 4.0000e-02, 4.0000e+00, 9.5482e+04, 1.0170e+03],\n",
       "          [3.0000e+00, 1.0000e+00, 1.0000e-01, 3.6000e+01, 4.4312e+04, 9.6000e+02],\n",
       "          [3.0000e+00, 2.0000e+00, 3.5400e+00, 1.8000e+01, 4.2240e+04, 1.8220e+03],\n",
       "          [2.0000e+00, 2.0000e+00, 3.3000e-01, 2.8000e+01, 2.7609e+04, 1.0500e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 3.0340e+01, 9.0000e+00, 3.2570e+04, 1.8220e+03],\n",
       "          [2.0000e+00, 1.0000e+00, 7.0000e-02, 3.9000e+01, 1.7851e+04, 9.8400e+02],\n",
       "          [5.0000e+00, 6.0000e+00, 5.1200e+00, 3.9000e+01, 1.9034e+04, 6.7200e+03],\n",
       "          [4.0000e+00, 3.0000e+00, 3.3000e-01, 4.5000e+01, 7.8253e+04, 2.0710e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 3.9000e+00, 1.5000e+01, 6.0175e+04, 1.8220e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 2.9513e+02, 4.5000e+01, 7.5974e+04, 1.8220e+03],\n",
       "          [4.0000e+00, 3.0000e+00, 9.8000e-01, 4.0000e+00, 9.3561e+04, 2.5650e+03],\n",
       "          [2.0000e+00, 2.0000e+00, 3.3000e-01, 1.9000e+01, 7.0737e+04, 1.1080e+03]]),\n",
       "  tensor([ 240000.,  770000.,  575000.,  420000.,  475000.,  309336.,  439000.,\n",
       "            16500.,  314400., 2900000.,   81000.,  322848.,   74900.,   90000.,\n",
       "           725000.,  232900.,   49900.,  278000., 1229000.,  224900.,  335000.,\n",
       "           109000.,   63720.,  139900.,  319800.,   43000., 3595000.,  362260.,\n",
       "           109000.,  664043.,  525000.,   95000.])],\n",
       " [tensor([[3.0000e+00, 2.0000e+00, 1.0000e+01, 4.5000e+01, 7.6519e+04, 1.8220e+03],\n",
       "          [3.0000e+00, 1.0000e+00, 1.7000e-01, 4.5000e+01, 7.8064e+04, 7.6000e+02],\n",
       "          [3.0000e+00, 2.0000e+00, 3.0000e-01, 5.1000e+01, 5.3188e+04, 2.1710e+03],\n",
       "          [3.0000e+00, 1.0000e+00, 1.7000e-01, 3.6000e+01, 4.3068e+04, 1.0400e+03],\n",
       "          [2.0000e+00, 2.0000e+00, 1.7000e-01, 2.4000e+01, 5.5433e+04, 2.7640e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 5.2000e-01, 2.8000e+01, 2.8715e+04, 1.9440e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 2.5600e+01, 2.5000e+01, 6.5620e+04, 1.8220e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 6.2600e+00, 1.9000e+01, 7.1275e+04, 1.8220e+03],\n",
       "          [2.0000e+00, 1.0000e+00, 5.0000e-02, 3.2000e+01, 7.2030e+03, 5.7600e+02],\n",
       "          [3.0000e+00, 1.0000e+00, 1.1000e-01, 9.0000e+00, 3.3311e+04, 9.9800e+02],\n",
       "          [3.0000e+00, 2.0000e+00, 9.1000e-01, 1.0000e+01, 3.0548e+04, 1.8220e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 3.3000e-01, 1.0000e+01, 3.0228e+04, 2.1710e+03],\n",
       "          [2.0000e+00, 2.0000e+00, 1.7000e-01, 9.0000e+00, 3.4759e+04, 1.4670e+03],\n",
       "          [4.0000e+00, 2.0000e+00, 1.2800e+00, 4.5000e+01, 7.7808e+04, 2.3750e+03],\n",
       "          [1.0000e+00, 2.0000e+00, 2.0000e-02, 2.4000e+01, 5.5114e+04, 1.0020e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 5.0000e-01, 2.8000e+01, 2.7817e+04, 1.8220e+03],\n",
       "          [4.0000e+00, 2.0000e+00, 2.3000e-01, 3.0000e+00, 8.5204e+04, 2.2640e+03],\n",
       "          [2.0000e+00, 2.0000e+00, 1.6000e-01, 4.0000e+00, 9.1401e+04, 8.8500e+02],\n",
       "          [4.0000e+00, 3.0000e+00, 1.0000e+00, 4.5000e+01, 7.8363e+04, 2.8700e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 3.3000e-01, 5.1000e+01, 5.3191e+04, 2.0920e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 1.6360e+01, 2.6000e+01, 3.9574e+04, 1.8220e+03],\n",
       "          [4.0000e+00, 3.0000e+00, 1.7000e-01, 9.0000e+00, 3.2712e+04, 2.4040e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 2.3000e-01, 9.0000e+00, 3.3909e+04, 1.5660e+03],\n",
       "          [2.0000e+00, 2.0000e+00, 3.3000e-01, 9.0000e+00, 3.3916e+04, 8.8300e+02],\n",
       "          [5.0000e+00, 4.0000e+00, 3.2000e-01, 2.4000e+01, 5.5044e+04, 3.7140e+03],\n",
       "          [3.0000e+00, 1.0000e+00, 2.9000e-01, 9.0000e+00, 3.3901e+04, 1.4150e+03],\n",
       "          [2.0000e+00, 1.0000e+00, 2.9000e-01, 2.5000e+01, 6.3077e+04, 8.3200e+02],\n",
       "          [3.0000e+00, 2.0000e+00, 8.0000e+00, 4.6000e+01, 8.4535e+04, 1.8220e+03],\n",
       "          [3.0000e+00, 2.0000e+00, 7.1800e+00, 2.6000e+01, 3.9110e+04, 1.8220e+03],\n",
       "          [1.0000e+00, 1.0000e+00, 1.4000e-01, 2.5000e+01, 6.5265e+04, 6.5000e+02],\n",
       "          [5.0000e+00, 4.0000e+00, 1.7000e-01, 9.0000e+00, 3.4786e+04, 3.6110e+03],\n",
       "          [4.0000e+00, 5.0000e+00, 4.2000e-01, 5.1000e+01, 5.4155e+04, 4.1450e+03]]),\n",
       "  tensor([ 164990.,   49900.,  569900.,  165000.,  402961.,  230000.,  125000.,\n",
       "            80000.,  155000.,  125000.,  129000.,  285900.,  275000.,  475000.,\n",
       "           239900.,   85000.,  520000.,  409000.,  330000., 1195000.,  168900.,\n",
       "           414990.,  545000.,  179999.,  569900.,  299900.,  125000.,   79000.,\n",
       "           193860.,   56000.,  849000.,  599900.])])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE: int = 32;\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame) -> None:\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        col_names = [col for col in self.df.columns if col != \"price\"]\n",
    "        features = torch.tensor(self.df.iloc[index][col_names].values, dtype=torch.float32)\n",
    "        label = torch.tensor(self.df.iloc[index]['price'], dtype=torch.float32)\n",
    "\n",
    "        return features, label;\n",
    "\n",
    "\n",
    "train_df, test_df = train_test_split(whole_df, test_size=0.2, train_size=0.8);\n",
    "\n",
    "train_dataset = CustomDataset(train_df);\n",
    "test_dataset = CustomDataset(test_df);\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True);\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False);\n",
    "\n",
    "next(iter(train_loader)), next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('input.weight',\n",
       "              tensor([[ 0.1864, -0.3295, -0.3936, -0.0234,  0.1892,  0.1117],\n",
       "                      [-0.3620,  0.1725,  0.3694,  0.0908,  0.2562,  0.1671],\n",
       "                      [-0.3317, -0.2761, -0.0457, -0.1734,  0.0671,  0.3174],\n",
       "                      ...,\n",
       "                      [ 0.1294,  0.1375, -0.2727, -0.3260,  0.3195,  0.3195],\n",
       "                      [ 0.3555,  0.3024,  0.0314, -0.0733,  0.1427, -0.1676],\n",
       "                      [-0.0467, -0.3274,  0.0170,  0.0425,  0.0430,  0.0836]],\n",
       "                     device='cuda:0')),\n",
       "             ('input.bias',\n",
       "              tensor([ 0.1869,  0.1592, -0.0404,  0.1091, -0.3488, -0.2420,  0.1016, -0.2041,\n",
       "                       0.2177,  0.3118, -0.0114,  0.0813,  0.2784, -0.0549,  0.3290, -0.1638,\n",
       "                      -0.1380, -0.0228, -0.3391, -0.1975,  0.3225,  0.2774,  0.1266,  0.4001,\n",
       "                       0.0130, -0.3547, -0.0322,  0.1195, -0.0232,  0.0562, -0.1198, -0.1237,\n",
       "                       0.3163,  0.0163, -0.0440, -0.3766, -0.2129, -0.2857,  0.1973,  0.2149,\n",
       "                       0.0354,  0.1550,  0.3829,  0.2492,  0.1314,  0.3377,  0.2752,  0.3411,\n",
       "                      -0.2095,  0.1087,  0.1775, -0.1773,  0.1767, -0.1471,  0.2236, -0.2985,\n",
       "                      -0.2626, -0.1997, -0.1081, -0.2539, -0.2972, -0.2313,  0.2262, -0.2181,\n",
       "                       0.3423,  0.3459,  0.3413,  0.1103,  0.3195,  0.3103,  0.3756, -0.0110,\n",
       "                      -0.0598,  0.2997,  0.0154, -0.3752, -0.3050, -0.0463, -0.1365,  0.3281,\n",
       "                       0.0378, -0.1814, -0.1638, -0.0741,  0.3130,  0.2837, -0.1733,  0.3988,\n",
       "                       0.3295, -0.2229, -0.0822,  0.3507,  0.3233, -0.2324,  0.0707,  0.0129,\n",
       "                       0.1618, -0.4042,  0.3337, -0.1612,  0.0967, -0.1580, -0.1433, -0.1235,\n",
       "                       0.2552, -0.2629,  0.0145, -0.2917,  0.1388, -0.3347,  0.2784, -0.1814,\n",
       "                       0.1811,  0.0254, -0.1091, -0.3601, -0.2334,  0.0908,  0.3719, -0.2534,\n",
       "                       0.2234,  0.2490,  0.1855, -0.1271,  0.2579, -0.1072, -0.0846,  0.2213,\n",
       "                      -0.3563, -0.0929, -0.2217,  0.3123, -0.2161,  0.0660, -0.2739, -0.1024,\n",
       "                      -0.1101, -0.3676, -0.0770, -0.0862, -0.2989,  0.2576, -0.1856,  0.1976,\n",
       "                      -0.1942,  0.1086,  0.2209, -0.3856, -0.1700,  0.3538, -0.2045, -0.1137,\n",
       "                      -0.1396, -0.3232, -0.3605,  0.0848, -0.2253,  0.0192, -0.3775, -0.2721,\n",
       "                       0.3389,  0.3424, -0.1658,  0.0469, -0.3067,  0.0639,  0.3521, -0.1597,\n",
       "                       0.0906,  0.3029, -0.3990, -0.2744,  0.3768,  0.0804,  0.0145,  0.3825,\n",
       "                       0.2839, -0.1649, -0.1075,  0.2703,  0.0399, -0.2959, -0.4062,  0.1264,\n",
       "                       0.0399,  0.2064, -0.0962, -0.3348,  0.1222,  0.2267, -0.3569,  0.1355,\n",
       "                      -0.2919, -0.1956,  0.1726,  0.3115, -0.0587,  0.2266, -0.3534,  0.2742,\n",
       "                       0.3852, -0.1832, -0.2086,  0.2106, -0.0823, -0.3622, -0.1494,  0.3672,\n",
       "                       0.1679,  0.3385,  0.0243, -0.3486, -0.3301, -0.1322,  0.0720, -0.1242,\n",
       "                       0.3164,  0.1275, -0.4027, -0.3017,  0.2592,  0.3506, -0.2439,  0.3642,\n",
       "                      -0.2000, -0.1181,  0.1855,  0.0230,  0.2255,  0.4064, -0.3754,  0.1569,\n",
       "                       0.0966, -0.2788, -0.3309, -0.3120, -0.0662,  0.1610, -0.3963, -0.3429,\n",
       "                       0.1593, -0.1177, -0.3984,  0.1815, -0.2147,  0.3255,  0.2371, -0.2579,\n",
       "                      -0.0101, -0.2355, -0.3888, -0.3354, -0.3450, -0.1390, -0.0255,  0.3370],\n",
       "                     device='cuda:0')),\n",
       "             ('block.0.weight',\n",
       "              tensor([[-0.0078,  0.0558, -0.0423,  ...,  0.0261, -0.0255, -0.0123],\n",
       "                      [ 0.0477, -0.0599, -0.0506,  ...,  0.0270,  0.0386,  0.0258],\n",
       "                      [-0.0260, -0.0118,  0.0359,  ...,  0.0511,  0.0619, -0.0002],\n",
       "                      ...,\n",
       "                      [ 0.0090,  0.0053, -0.0036,  ..., -0.0169,  0.0156, -0.0094],\n",
       "                      [ 0.0266,  0.0119, -0.0391,  ...,  0.0054,  0.0477, -0.0207],\n",
       "                      [-0.0305, -0.0189, -0.0507,  ...,  0.0620,  0.0436,  0.0121]],\n",
       "                     device='cuda:0')),\n",
       "             ('block.0.bias',\n",
       "              tensor([-5.4870e-02,  1.1102e-02, -2.4610e-02, -6.1974e-02, -4.7996e-02,\n",
       "                      -5.1910e-02,  3.2671e-02,  7.8272e-03,  3.7703e-02,  2.9084e-02,\n",
       "                       5.3962e-02,  1.2970e-02, -2.2665e-02,  3.2200e-02, -1.1144e-02,\n",
       "                      -3.4812e-02,  2.3096e-02,  5.8394e-02, -4.4077e-02, -5.3364e-02,\n",
       "                       6.1679e-02, -2.6403e-02, -3.3526e-02,  2.9385e-02, -2.2108e-02,\n",
       "                       3.6634e-02,  1.6010e-03, -3.4941e-02,  2.7619e-02, -3.2140e-02,\n",
       "                       3.5409e-03, -4.0577e-02, -5.8743e-02,  5.7881e-04, -3.8230e-02,\n",
       "                      -1.5689e-02, -1.4582e-02,  3.3643e-02, -3.0616e-02, -5.6838e-02,\n",
       "                      -2.4120e-02, -3.2401e-02, -4.8069e-02,  5.7158e-02,  1.7271e-02,\n",
       "                       3.3858e-02,  5.4587e-02, -5.0707e-02,  4.1003e-02, -1.3480e-02,\n",
       "                      -2.0457e-02,  2.3056e-02, -3.3456e-02, -3.3058e-02, -6.0471e-02,\n",
       "                      -1.3042e-02,  3.4995e-03,  5.9491e-02,  6.0767e-02,  3.9110e-02,\n",
       "                      -1.8581e-02,  2.8672e-02,  1.9947e-02,  2.0452e-02, -2.5356e-02,\n",
       "                      -5.9352e-02,  5.0236e-02,  3.3944e-02,  2.7103e-02,  5.4570e-02,\n",
       "                      -3.5602e-03,  6.4324e-03, -4.3507e-02,  5.7004e-02,  4.1203e-02,\n",
       "                      -1.1255e-02,  3.1896e-02, -4.1973e-02, -3.1844e-02,  9.9505e-03,\n",
       "                      -5.5770e-02,  4.7238e-02, -4.1082e-03, -1.2478e-02, -3.1029e-02,\n",
       "                      -2.2247e-02,  1.1339e-02,  4.0717e-02, -5.2617e-03,  1.3512e-02,\n",
       "                      -4.8664e-02,  2.4477e-02, -2.0799e-02, -2.2857e-02,  1.1905e-02,\n",
       "                       4.9504e-02, -2.4310e-02, -5.3354e-02, -2.8268e-02, -4.9496e-02,\n",
       "                       3.4094e-02, -1.2133e-02,  2.8333e-02,  5.2988e-02, -4.8002e-02,\n",
       "                       2.9560e-03,  1.3197e-02,  5.1514e-03, -1.9357e-02, -3.7911e-02,\n",
       "                      -4.3653e-02,  1.7568e-02,  3.1761e-03,  3.2708e-02, -2.3299e-02,\n",
       "                      -5.6829e-02, -1.1155e-02,  5.1012e-02, -6.4202e-03, -3.4884e-03,\n",
       "                       1.4675e-02, -2.6819e-02, -1.0804e-02,  2.4546e-02,  7.8161e-03,\n",
       "                      -4.5513e-02,  4.2508e-02, -6.8934e-03, -5.7839e-02, -3.1306e-02,\n",
       "                      -9.4739e-03,  4.7516e-02,  1.8341e-02, -1.9487e-02,  5.1208e-02,\n",
       "                      -1.0919e-02, -7.8019e-03, -3.3003e-02,  1.1927e-02, -2.6904e-02,\n",
       "                       3.9468e-02, -2.1079e-02,  8.1937e-03,  4.2571e-02,  3.1195e-03,\n",
       "                       4.4743e-02, -6.0735e-02,  1.5505e-02,  2.2253e-02, -4.3227e-02,\n",
       "                       2.7333e-02, -1.9026e-02,  1.2789e-02, -1.7963e-03, -4.8000e-03,\n",
       "                      -4.1165e-02,  2.1835e-02, -5.5223e-02, -1.3560e-02, -1.9308e-02,\n",
       "                       5.7902e-02,  5.1217e-03,  6.5370e-03,  6.3917e-03, -5.1094e-02,\n",
       "                      -4.3580e-02,  2.3872e-02, -3.9266e-02, -1.2966e-02,  1.3876e-02,\n",
       "                       3.0594e-02, -1.8423e-02, -3.8899e-02, -4.1855e-02,  3.9366e-02,\n",
       "                      -2.5348e-02, -3.6405e-02,  1.1188e-02,  2.1588e-02, -4.8072e-02,\n",
       "                       2.8679e-02,  3.7044e-02, -3.7707e-02, -4.1811e-02, -1.1928e-02,\n",
       "                       1.0247e-02,  2.2076e-02,  7.1332e-03, -4.6576e-02,  1.4863e-02,\n",
       "                       2.0596e-02, -2.2060e-02,  1.8386e-02,  2.3263e-02,  9.4302e-03,\n",
       "                      -3.6173e-03,  2.5384e-02, -4.5524e-02,  3.8233e-02,  3.4388e-02,\n",
       "                       5.4322e-03, -4.7331e-02, -5.7833e-02, -3.6041e-04,  1.8167e-02,\n",
       "                      -6.0928e-02, -3.6295e-02, -5.4977e-02, -3.4783e-02, -4.4952e-02,\n",
       "                       4.8484e-02,  3.4243e-02,  2.1872e-02,  5.0652e-02, -5.3967e-02,\n",
       "                       3.8180e-02,  1.1235e-02,  1.6918e-02, -2.2027e-02,  1.9467e-02,\n",
       "                      -2.8425e-02,  7.2314e-03,  9.5062e-03,  2.6079e-02,  1.7969e-02,\n",
       "                       2.8006e-03,  2.5152e-04, -1.8907e-02,  2.9476e-02, -1.5576e-02,\n",
       "                       6.1814e-02, -4.5875e-02, -4.6393e-02, -5.7094e-02, -2.6122e-02,\n",
       "                      -5.1102e-02,  3.9864e-02, -5.4320e-02,  3.1808e-02, -2.7197e-02,\n",
       "                      -4.3535e-02, -1.4969e-02,  4.5962e-02, -6.5826e-05, -3.9803e-02,\n",
       "                      -3.2145e-02,  6.0549e-02,  2.5172e-02, -2.7396e-02, -5.3100e-02,\n",
       "                       3.6455e-02, -1.6616e-02,  1.9602e-02, -5.6565e-02, -4.0642e-02,\n",
       "                       3.9161e-02], device='cuda:0')),\n",
       "             ('block.2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('block.2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('block.2.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('block.2.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('block.2.num_batches_tracked', tensor(0, device='cuda:0')),\n",
       "             ('classifier.weight',\n",
       "              tensor([[ 6.1206e-02, -3.9204e-02,  4.7926e-02,  1.8323e-02, -3.9778e-02,\n",
       "                        1.4803e-02,  1.9239e-02,  4.7701e-02,  4.7380e-02,  4.9466e-03,\n",
       "                       -4.2370e-02,  5.4067e-02, -2.0313e-02, -3.8314e-02, -2.8530e-02,\n",
       "                        2.3143e-02,  2.2111e-02,  1.3152e-02, -5.2207e-02,  2.1504e-02,\n",
       "                        4.6771e-02,  2.7014e-02, -5.0606e-02,  9.6038e-03,  3.3298e-02,\n",
       "                       -3.7160e-03, -3.8451e-02,  6.2082e-02,  5.9499e-02,  2.0130e-03,\n",
       "                        4.3733e-02,  1.6860e-02, -1.7504e-02, -1.1049e-02, -2.6790e-03,\n",
       "                        5.7607e-02,  3.4292e-02, -6.1414e-02, -3.4043e-02, -3.6538e-02,\n",
       "                        2.6986e-02, -3.3925e-02, -4.1856e-02,  4.2991e-02, -4.7486e-02,\n",
       "                        1.1760e-02, -3.4072e-02, -3.8848e-02, -4.0289e-02,  2.9842e-02,\n",
       "                        4.5204e-02, -4.7811e-02,  3.0342e-02,  1.9482e-03, -2.5356e-02,\n",
       "                        4.7440e-02, -3.9878e-02,  4.7637e-02, -2.6268e-02, -4.3351e-03,\n",
       "                        4.2703e-02,  3.5983e-02,  1.0938e-02, -1.6823e-02, -3.2344e-02,\n",
       "                        3.9059e-02, -2.4907e-02,  5.4310e-02, -3.2325e-02,  8.4195e-03,\n",
       "                       -5.4477e-02,  5.0355e-02, -5.8870e-02,  9.9208e-03, -7.2979e-03,\n",
       "                        1.2161e-02, -5.4960e-02,  4.5201e-02, -5.0996e-02,  3.4974e-02,\n",
       "                       -3.8844e-02, -6.2153e-02, -6.2349e-02,  5.9292e-02,  6.1927e-02,\n",
       "                        3.5867e-02, -3.0152e-02,  1.8508e-02, -3.6914e-02,  1.8192e-02,\n",
       "                        1.7595e-02,  1.0227e-02,  2.7855e-02, -3.7930e-02, -1.1578e-02,\n",
       "                        1.5254e-02,  5.6140e-05, -4.6744e-02, -2.5338e-02,  3.4499e-02,\n",
       "                       -4.1485e-02,  1.8449e-02,  3.5146e-02,  5.4092e-02,  6.9445e-03,\n",
       "                        2.8597e-02,  5.7339e-02, -1.6334e-02, -3.5360e-04,  1.2903e-02,\n",
       "                        6.1446e-02, -6.2482e-03, -6.2187e-02,  4.5370e-03, -1.6826e-03,\n",
       "                        1.4886e-03, -5.3456e-02, -5.0550e-02,  1.5990e-02,  4.4552e-02,\n",
       "                       -4.6048e-02, -2.4180e-02, -2.7894e-03,  3.2696e-02, -4.4683e-02,\n",
       "                        6.2364e-02,  3.6149e-02,  1.6249e-02, -5.4354e-02, -5.7747e-03,\n",
       "                       -4.1581e-03, -5.4773e-02, -3.4051e-04,  3.3394e-02,  3.7564e-02,\n",
       "                       -5.2536e-02,  9.2525e-03,  3.3847e-02,  1.8224e-02,  1.4651e-02,\n",
       "                       -6.0882e-02,  3.1063e-02, -4.1929e-02,  5.2869e-02, -2.8296e-02,\n",
       "                       -8.5157e-03, -1.3147e-02, -2.5878e-02, -5.1257e-02, -5.4285e-03,\n",
       "                        1.9146e-02, -5.1631e-02, -3.7653e-02,  2.3198e-02, -4.6151e-02,\n",
       "                        4.8229e-02,  2.1211e-02, -1.2314e-02,  5.4097e-02,  2.1718e-02,\n",
       "                       -5.3920e-02,  5.0156e-02, -2.5024e-02,  5.7649e-02, -6.0563e-02,\n",
       "                       -3.8183e-02,  8.7429e-03, -6.1299e-02,  3.9047e-02,  1.6015e-02,\n",
       "                       -1.0072e-02,  5.4576e-02, -5.2556e-02, -3.0055e-02,  1.0763e-02,\n",
       "                       -2.8557e-02, -1.2376e-03,  2.2881e-02,  5.7984e-02, -5.6098e-02,\n",
       "                        4.1756e-03, -5.1570e-02, -2.4548e-02,  5.6244e-02, -1.9924e-02,\n",
       "                       -5.3311e-02, -2.4192e-02,  3.8971e-02,  1.8592e-02, -4.4932e-03,\n",
       "                        2.8242e-02, -3.9485e-02, -4.7619e-02,  3.6047e-03,  5.5103e-02,\n",
       "                        5.4227e-02,  2.5712e-02,  5.4262e-02, -2.3667e-02,  5.5501e-02,\n",
       "                        1.0799e-02,  1.4289e-02, -3.6191e-02, -2.3352e-02, -3.1567e-02,\n",
       "                       -2.5421e-02,  7.2808e-03, -3.3944e-02, -4.1357e-02,  2.3218e-02,\n",
       "                       -2.7518e-02, -1.0643e-02, -5.9336e-02,  4.0163e-02, -4.8026e-02,\n",
       "                       -3.7739e-02, -5.4455e-02, -2.8221e-02, -5.6641e-02,  1.4951e-02,\n",
       "                        7.5321e-03,  4.4430e-02, -3.8526e-02,  2.5481e-02,  6.8255e-03,\n",
       "                       -4.9406e-02, -5.1004e-02, -5.5942e-02,  2.9807e-02, -6.0916e-02,\n",
       "                        6.1675e-02,  4.9105e-02, -4.1703e-02, -2.9928e-02,  3.2175e-02,\n",
       "                        7.3483e-03,  4.6492e-02, -7.0627e-03, -1.8371e-02, -5.3127e-02,\n",
       "                       -5.7266e-02,  8.6209e-03,  1.8970e-02,  3.2821e-02,  2.6403e-02,\n",
       "                       -1.3963e-04, -2.6631e-02,  5.2347e-02, -5.3928e-02, -6.2041e-02,\n",
       "                       -4.5111e-02, -3.8823e-02, -5.1127e-02,  9.2465e-03, -5.4384e-02,\n",
       "                       -7.3188e-03]], device='cuda:0')),\n",
       "             ('classifier.bias', tensor([-0.0420], device='cuda:0'))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LinearBaseline(nn.Module):\n",
    "    def __init__(self, input_features, num_blocks, hidden_units=64, dropout=0.3) -> None:\n",
    "        super().__init__();\n",
    "\n",
    "        self.num_blocks = num_blocks;\n",
    "\n",
    "        self.input = nn.Linear(in_features=input_features, out_features=hidden_units);\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_units),\n",
    "            nn.Dropout(dropout)\n",
    "        );\n",
    "    \n",
    "        self.classifier = nn.Linear(in_features=hidden_units, out_features=1);\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.input(x);\n",
    "        for _ in range(self.num_blocks):\n",
    "            x = self.block(x);\n",
    "\n",
    "        return self.classifier(x);\n",
    "\n",
    "model = LinearBaseline(hidden_units=256,\n",
    "                       dropout=0.3,\n",
    "                       input_features=len(next(iter(train_loader))[0][0]),\n",
    "                       num_blocks=3).to(DEVICE);\n",
    "\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Step\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "    model: LinearBaseline,\n",
    "    loader: DataLoader,\n",
    "    loss_fn: nn.Module,\n",
    "    optim: torch.optim.Optimizer) -> Tuple[float, float]:\n",
    "\n",
    "    running_loss = 0.0;\n",
    "    running_acc = 0.0;\n",
    "    total_samples = 0;\n",
    "    \n",
    "    for X, y in tqdm(loader):\n",
    "        X: torch.Tensor = X.to(DEVICE);\n",
    "        y: torch.Tensor = y.to(DEVICE);\n",
    "\n",
    "        # Ensure model output matches target shape\n",
    "        outputs: torch.Tensor = model(X).squeeze(-1);\n",
    "\n",
    "        if outputs.shape == y.shape:\n",
    "            loss = loss_fn(outputs, y);\n",
    "            optim.zero_grad();\n",
    "            loss.backward();\n",
    "            optim.step();\n",
    "            running_loss += loss.item() * X.size(0);\n",
    "            running_acc += utils.batchAccuracy(outputs, y) * X.size(0);\n",
    "            total_samples += X.size(0);\n",
    "\n",
    "    \n",
    "    avg_loss = running_loss / total_samples if total_samples > 0 else 0.0\n",
    "    avg_acc = running_acc / total_samples if total_samples > 0 else 0.0\n",
    "    \n",
    "    return avg_loss, avg_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Step\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(\n",
    "    model: LinearBaseline,\n",
    "    loader: DataLoader,\n",
    "    loss_fn: nn.Module) -> Tuple[float, float]:\n",
    "    \n",
    "    running_loss = 0.0;\n",
    "    running_acc = 0.0;\n",
    "    total_samples = 0;\n",
    "    \n",
    "    for X, y in tqdm(loader):\n",
    "        X: torch.Tensor = X.to(DEVICE);\n",
    "        y: torch.Tensor = y.to(DEVICE);\n",
    "\n",
    "        outputs: torch.Tensor = model(X).squeeze(-1);\n",
    "\n",
    "        if outputs.shape == y.shape:\n",
    "            loss = loss_fn(outputs, y)\n",
    "            running_loss += loss.item() * X.size(0)  \n",
    "            running_acc += utils.batchAccuracy(outputs, y) * X.size(0) \n",
    "            total_samples += X.size(0)\n",
    "    \n",
    "    avg_loss = running_loss / total_samples if total_samples > 0 else 0.0\n",
    "    avg_acc = running_acc / total_samples if total_samples > 0 else 0.0\n",
    "    \n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [10:24<00:00, 56.59it/s]\n",
      "100%|██████████| 8830/8830 [01:59<00:00, 73.68it/s]\n",
      "  4%|▍         | 1/25 [12:24<4:57:36, 744.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2747516746498.4800%, Test Loss: 154952013531812822480060416.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [10:19<00:00, 57.00it/s]\n",
      "100%|██████████| 8830/8830 [01:57<00:00, 75.08it/s]\n",
      "  8%|▊         | 2/25 [24:41<4:43:41, 740.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2732628073961.0327%, Test Loss: inf%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [10:23<00:00, 56.64it/s]\n",
      "100%|██████████| 8830/8830 [01:58<00:00, 74.37it/s]\n",
      " 12%|█▏        | 3/25 [37:03<4:31:44, 741.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2726381211521.6655%, Test Loss: inf%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [10:31<00:00, 55.90it/s]\n",
      "100%|██████████| 8830/8830 [01:57<00:00, 75.19it/s]\n",
      " 16%|█▌        | 4/25 [49:32<4:20:31, 744.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2715735750212.2788%, Test Loss: 37338669277447863205626107658240.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [09:57<00:00, 59.08it/s]\n",
      "100%|██████████| 8830/8830 [01:49<00:00, 80.39it/s]\n",
      " 20%|██        | 5/25 [1:01:20<4:03:42, 731.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2712853070156.1948%, Test Loss: inf%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [09:51<00:00, 59.75it/s]\n",
      "100%|██████████| 8830/8830 [01:56<00:00, 75.81it/s]\n",
      " 24%|██▍       | 6/25 [1:13:08<3:48:59, 723.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2710623312942.9858%, Test Loss: inf%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [10:12<00:00, 57.67it/s]\n",
      "100%|██████████| 8830/8830 [01:55<00:00, 76.74it/s]\n",
      " 28%|██▊       | 7/25 [1:25:15<3:37:22, 724.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2705179122644.8193%, Test Loss: inf%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [09:52<00:00, 59.56it/s]\n",
      "100%|██████████| 8830/8830 [01:50<00:00, 79.98it/s]\n",
      " 32%|███▏      | 8/25 [1:36:59<3:23:23, 717.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2705170466531.1426%, Test Loss: inf%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [09:59<00:00, 58.87it/s]\n",
      "100%|██████████| 8830/8830 [02:02<00:00, 71.81it/s]\n",
      " 36%|███▌      | 9/25 [1:49:02<3:11:50, 719.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2700338435456.2036%, Test Loss: 276115403090864570368.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [10:24<00:00, 56.59it/s]\n",
      "100%|██████████| 8830/8830 [02:00<00:00, 73.52it/s]\n",
      " 40%|████      | 10/25 [2:01:26<3:01:46, 727.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2697953134104.0801%, Test Loss: 3475624067224278925312.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [09:57<00:00, 59.16it/s]\n",
      "100%|██████████| 8830/8830 [01:47<00:00, 81.89it/s]\n",
      " 44%|████▍     | 11/25 [2:13:11<2:48:03, 720.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2691089563680.5874%, Test Loss: 186353754982048935030435086336.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [09:48<00:00, 60.01it/s]\n",
      "100%|██████████| 8830/8830 [01:51<00:00, 78.94it/s]\n",
      " 48%|████▊     | 12/25 [2:24:51<2:34:44, 714.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2691452383839.2310%, Test Loss: inf%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [09:55<00:00, 59.31it/s]\n",
      "100%|██████████| 8830/8830 [01:51<00:00, 78.99it/s]\n",
      " 52%|█████▏    | 13/25 [2:36:38<2:22:25, 712.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2685247794823.0845%, Test Loss: 26170228504047237457772544.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [09:53<00:00, 59.52it/s]\n",
      "100%|██████████| 8830/8830 [01:50<00:00, 79.68it/s]\n",
      " 56%|█████▌    | 14/25 [2:48:23<2:10:07, 709.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2682871251754.9170%, Test Loss: 348051078240012544.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [09:47<00:00, 60.08it/s]\n",
      "100%|██████████| 8830/8830 [01:51<00:00, 79.49it/s]\n",
      " 60%|██████    | 15/25 [3:00:02<1:57:44, 706.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2676801363377.5122%, Test Loss: 166217420514460467200.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [09:50<00:00, 59.86it/s]\n",
      "100%|██████████| 8830/8830 [01:48<00:00, 81.26it/s]\n",
      " 64%|██████▍   | 16/25 [3:11:40<1:45:37, 704.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2672787664249.4263%, Test Loss: 42422360036954980352.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [09:37<00:00, 61.11it/s]\n",
      "100%|██████████| 8830/8830 [01:49<00:00, 80.78it/s]\n",
      " 68%|██████▊   | 17/25 [3:23:08<1:33:12, 699.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2671256723421.3540%, Test Loss: 8453797353868136838747652096.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [09:51<00:00, 59.72it/s]\n",
      "100%|██████████| 8830/8830 [01:55<00:00, 76.30it/s]\n",
      " 72%|███████▏  | 18/25 [3:34:55<1:21:50, 701.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2667694926148.9395%, Test Loss: 184609765483159470341095424.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [10:07<00:00, 58.14it/s]\n",
      "100%|██████████| 8830/8830 [01:56<00:00, 75.97it/s]\n",
      " 76%|███████▌  | 19/25 [3:46:59<1:10:49, 708.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2663414073462.7744%, Test Loss: 2095119024013583417787174724042752.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [09:54<00:00, 59.39it/s]\n",
      "100%|██████████| 8830/8830 [01:44<00:00, 84.24it/s]\n",
      " 80%|████████  | 20/25 [3:58:38<58:48, 705.60s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2666645247376.4390%, Test Loss: 15238351010300808.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [08:43<00:00, 67.45it/s]\n",
      "100%|██████████| 8830/8830 [01:44<00:00, 84.73it/s]\n",
      " 84%|████████▍ | 21/25 [4:09:06<45:29, 682.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2664673791731.0229%, Test Loss: 393570601568924928.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [09:33<00:00, 61.54it/s]\n",
      "100%|██████████| 8830/8830 [01:50<00:00, 80.05it/s]\n",
      " 88%|████████▊ | 22/25 [4:20:30<34:08, 682.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2665785225935.8955%, Test Loss: 95703121622995504.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [09:16<00:00, 63.43it/s]\n",
      "100%|██████████| 8830/8830 [01:52<00:00, 78.57it/s]\n",
      " 92%|█████████▏| 23/25 [4:31:39<22:37, 678.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2663226798559.8384%, Test Loss: 9162036833022573568.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [09:34<00:00, 61.46it/s]\n",
      "100%|██████████| 8830/8830 [01:48<00:00, 81.35it/s]\n",
      " 96%|█████████▌| 24/25 [4:43:03<11:20, 680.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2661487537456.0176%, Test Loss: 170876709468083680.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35320/35320 [09:09<00:00, 64.25it/s]\n",
      "100%|██████████| 8830/8830 [01:49<00:00, 80.70it/s]\n",
      "100%|██████████| 25/25 [4:54:02<00:00, 705.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25\n",
      "Training Accuracy: 0.00%, Test Accuracy: 0.00%\n",
      "Training Loss: 2658720516697.4976%, Test Loss: 18481937625453801472.0000%\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2);\n",
    "loss_fn = torch.nn.MSELoss();\n",
    "EPOCHS = 25;\n",
    "\n",
    "# loop over the dataset multiple times\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    \n",
    "    model.train();\n",
    "    train_loss, train_acc = train_step(\n",
    "        loader=train_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        model=model,\n",
    "        optim=optimizer,\n",
    "    );\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        model.eval();\n",
    "        test_loss, test_acc = test_step(\n",
    "            loader=test_loader,\n",
    "            loss_fn=loss_fn,\n",
    "            model=model,\n",
    "        );\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\");\n",
    "    print(f\"Training Accuracy: {train_acc:.2f}%, Test Accuracy: {test_acc:.2f}%\");\n",
    "    print(f\"Training Loss: {train_loss:.4f}%, Test Loss: {test_loss:.4f}%\");\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 6).to(DEVICE);\n",
    "torch.onnx.export(model,\n",
    "                  dummy_input,\n",
    "                  f\"{dataset_outlier_mode}-model.onnx\",\n",
    "                  opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
